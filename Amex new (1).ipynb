{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e515afbc-418d-4c7d-be88-1ca805b7159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf0e976-c11e-4609-a388-ca6f9ecfb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_parquet('train_data.parquet')\n",
    "df_test=pd.read_parquet('test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3486f399-f38d-40c8-93be-c75e7d41db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the datatype of multiple columns from object to numerical\n",
    "\n",
    "def obj_to_num(df,low,high,arr):\n",
    "    all_f_cols = [f'f{i}' for i in range(low, high+1)]\n",
    "    exclude_cols = arr\n",
    "    cols_to_convert = [col for col in all_f_cols if col not in exclude_cols]\n",
    "\n",
    "    df[cols_to_convert] = df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff3c635-d872-44c9-b162-90a0db5b92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoder function\n",
    "\n",
    "def one_hot(df,col):\n",
    "    df[col] = df[col].fillna('Unknown')  # or 'None'\n",
    "\n",
    "    encoded = pd.get_dummies(df[col], prefix=col)\n",
    "    \n",
    "    df = pd.concat([df, encoded], axis=1)\n",
    "    df.drop(columns=[col,f'{col}_Unknown'],inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f96382-abc3-4633-9643-7a1dadc123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data type to numerical for relevant columns\n",
    "\n",
    "df_train=obj_to_num(df_train,1,51,['f42','f48','f50'])\n",
    "df_train=obj_to_num(df_train,58,225,[])\n",
    "df_train=obj_to_num(df_train,226,366,['f349', 'f354'])\n",
    "\n",
    "# changing the datatype of dependent variable\n",
    "\n",
    "df_train['y'] = pd.to_numeric(df_train['y'], errors='coerce')\n",
    "\n",
    "df_train['f48'] = pd.to_numeric(df_train['f48'], errors='coerce')\n",
    "df_train['f349'] = pd.to_numeric(df_train['f349'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f52f311a-a980-4e1e-afd2-0c999b775501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data type to numerical for relevant columns\n",
    "\n",
    "df_test=obj_to_num(df_test,1,51,['f42','f48','f50'])\n",
    "df_test=obj_to_num(df_test,58,225,[])\n",
    "df_test=obj_to_num(df_test,226,366,['f349', 'f354'])\n",
    "\n",
    "# changing the datatype of dependent variable\n",
    "\n",
    "# df_train['y'] = pd.to_numeric(df_train['y'], errors='coerce')\n",
    "\n",
    "df_test['f48'] = pd.to_numeric(df_test['f48'], errors='coerce')\n",
    "df_test['f349'] = pd.to_numeric(df_test['f349'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f0d517-80cd-4671-bb3d-c46377b0325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = one_hot(df_test, 'f42')\n",
    "df_train = one_hot(df_train, 'f42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452e7e7e-1b3e-41e3-8896-41e1262c6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test = one_hot(df_test, 'f54')\n",
    "df_test = one_hot(df_test, 'f55')\n",
    "df_test = one_hot(df_test, 'f56')\n",
    "df_test = one_hot(df_test, 'f57')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cbf21e3-b626-41f7-bc48-3868bc7079b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = one_hot(df_train, 'f54')\n",
    "df_train = one_hot(df_train, 'f55')\n",
    "df_train = one_hot(df_train, 'f56')\n",
    "df_train = one_hot(df_train, 'f57')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3aeb969-62f5-4ded-96e3-5e3c04e8bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['f53'] = df_train['f53'].map({'NY': 1, 'NN': 0})\n",
    "# df['your_column'] = df['your_column'].fillna(0)  # or .fillna(-1) if you want to distinguish None\n",
    "\n",
    "df_train['f53'] = df_train['f53'].replace({None: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b36820-7041-4ec9-8134-1ec44dee94b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91637\\AppData\\Local\\Temp\\ipykernel_25620\\1332517543.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_train['f354'] = df_train['f354'].replace({\n"
     ]
    }
   ],
   "source": [
    "## changin the data type with binary type categorical data\n",
    "\n",
    "df_train['f50'] = df_train['f50'].map({'Y': 1, 'N': 0})\n",
    "# df['your_column'] = df['your_column'].fillna(0)  # or .fillna(-1) if you want to distinguish None\n",
    "\n",
    "df_train['f50'] = df_train['f50'].replace({None: np.nan})\n",
    "\n",
    "\n",
    "df_train['f52'] = df_train['f52'].map({'Y': 1, 'N': 0})\n",
    "# df['your_column'] = df['your_column'].fillna(0)  # or .fillna(-1) if you want to distinguish None\n",
    "\n",
    "df_train['f52'] = df_train['f52'].replace({None: np.nan})\n",
    "\n",
    "\n",
    "df_train['f354'] = df_train['f354'].replace({\n",
    "    'Phase_1': 0,\n",
    "    'Rest': 1,\n",
    "    None: np.nan  # Explicitly convert None to NaN\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f122cb1-ffd2-4508-b26e-0caaeb8bf0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91637\\AppData\\Local\\Temp\\ipykernel_25620\\1071168181.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test['f354'] = df_test['f354'].replace({\n"
     ]
    }
   ],
   "source": [
    "## changin the data type with binary type categorical data\n",
    "\n",
    "df_test['f50'] = df_test['f50'].map({'Y': 1, 'N': 0})\n",
    "#df['your_column'] = df['your_column'].fillna(0)  # or .fillna(-1) if you want to distinguish None\n",
    " \n",
    "df_test['f50'] = df_test['f50'].replace({None: np.nan})\n",
    "\n",
    "\n",
    "df_test['f52'] = df_test['f52'].map({'Y': 1, 'N': 0})\n",
    "# df['your_column'] = df['your_column'].fillna(0)  # or .fillna(-1) if you want to distinguish None\n",
    "\n",
    "df_test['f52'] = df_test['f52'].replace({None: np.nan})\n",
    "\n",
    "\n",
    "df_test['f354'] = df_test['f354'].replace({\n",
    "    'Phase_1': 0,\n",
    "    'Rest': 1,\n",
    "    None: np.nan  # Explicitly convert None to NaN\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23c6c49d-f141-4916-aefc-194d4827dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['f53'] = df_test['f53'].map({'NY': 1, 'NN': 0})\n",
    "# df['your_column'] = df['your_column'].fillna(0)  # or .fillna(-1) if you want to distinguish None\n",
    "\n",
    "df_test['f53'] = df_test['f53'].replace({None: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0bcef0-9bbe-43da-aff5-89a41b068cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops the columns with only unique values 0 and NaN\n",
    "\n",
    "def drop_too(df,low,high):\n",
    "    cols = [f\"f{i}\" for i in range(low, high+1)]\n",
    "    \n",
    "    # Drop columns where the only unique values are [0.0, NaN] or [0, np.nan]\n",
    "    cols_to_drop = [\n",
    "        col for col in cols \n",
    "        if set(df[col].dropna().unique()) == {0} and df[col].isnull().any()\n",
    "    ]\n",
    "    \n",
    "    # Now drop them from the DataFrame\n",
    "    df= df.drop(columns=cols_to_drop, inplace=True),\n",
    "    return df,print(f\"Dropped columns: {cols_to_drop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "471fa862-ceb6-4b97-9b01-9b9eaafc6290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['f226', 'f229', 'f236', 'f238', 'f240', 'f243', 'f245', 'f246', 'f248', 'f249', 'f258', 'f259', 'f260', 'f262', 'f266', 'f267', 'f268', 'f270', 'f271', 'f277', 'f279', 'f281', 'f286', 'f287', 'f290', 'f291', 'f294', 'f295', 'f298', 'f300', 'f301', 'f303', 'f304', 'f307', 'f308', 'f309']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((None,), None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_too(df_train,226,309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd6cff1-8d9e-428d-850a-f74257201a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['f226', 'f229', 'f236', 'f238', 'f240', 'f243', 'f245', 'f246', 'f248', 'f249', 'f258', 'f259', 'f260', 'f262', 'f266', 'f267', 'f268', 'f270', 'f271', 'f277', 'f279', 'f281', 'f286', 'f287', 'f290', 'f291', 'f294', 'f295', 'f298', 'f300', 'f301', 'f303', 'f304', 'f307', 'f308', 'f309']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((None,), None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_too(df_test,226,309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c44789-cd8b-4b50-8e95-fee9ace2a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_zero_nan_columns(df):\n",
    "    \"\"\"\n",
    "    Drops columns from the DataFrame where the only unique non-null value is 0\n",
    "    and the rest are NaNs.\n",
    "    \n",
    "    Example: [0, NaN, NaN, 0] → drop\n",
    "    \"\"\"\n",
    "    cols_to_drop = [\n",
    "        col for col in df.columns\n",
    "        if set(df[col].dropna().unique()) == {0} and df[col].isnull().any()\n",
    "    ]\n",
    "    \n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    print(f\"✅ Dropped columns: {cols_to_drop}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e88f192-8315-4aac-bbe9-94caae702ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dropped columns: ['f14', 'f15', 'f16', 'f17', 'f19', 'f20', 'f21', 'f23', 'f24', 'f25', 'f62', 'f66', 'f80', 'f88', 'f102', 'f128', 'f129', 'f144', 'f145', 'f334', 'f335']\n",
      "✅ Dropped columns: ['f14', 'f15', 'f16', 'f19', 'f20', 'f21', 'f23', 'f24', 'f25', 'f62', 'f66', 'f71', 'f88', 'f102', 'f128', 'f129', 'f144', 'f145', 'f334', 'f335']\n"
     ]
    }
   ],
   "source": [
    "df_train=drop_zero_nan_columns(df_train)\n",
    "df_test=drop_zero_nan_columns(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39ae2d37-a38b-4350-a5f5-84f67a652f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_con(df):\n",
    "    bool_cols = df.select_dtypes(include='bool').columns\n",
    "    df[bool_cols] = df[bool_cols].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61b8b00b-37d8-44c8-ac0c-a0d41f78827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=bool_con(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74244392-1da8-48bf-b9a3-e1e75319b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=bool_con(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1464a3fd-2055-4045-a334-68869d9486bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['f59', 'f76']\n",
    "df_train.drop(columns=[col for col in cols_to_drop if col in df_train.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f59', 'f76']\n",
    "df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f123', 'f124','f125','f126']\n",
    "df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f123', 'f124','f125','f126']\n",
    "df_train.drop(columns=[col for col in cols_to_drop if col in df_train.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f146']\n",
    "df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f146']\n",
    "df_train.drop(columns=[col for col in cols_to_drop if col in df_train.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f199','f200','f201']\n",
    "df_train.drop(columns=[col for col in cols_to_drop if col in df_train.columns], inplace=True)\n",
    "cols_to_drop = ['f199','f200','f201']\n",
    "df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f310']\n",
    "df_train.drop(columns=[col for col in cols_to_drop if col in df_train.columns], inplace=True)\n",
    "cols_to_drop = ['f310']\n",
    "df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f332']\n",
    "df_train.drop(columns=[col for col in cols_to_drop if col in df_train.columns], inplace=True)\n",
    "cols_to_drop = ['f332']\n",
    "df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns], inplace=True)\n",
    "\n",
    "cols_to_drop = ['f353']\n",
    "df_train.drop(columns=[col for col in cols_to_drop if col in df_train.columns], inplace=True)\n",
    "cols_to_drop = ['f353']\n",
    "df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dae9112-8e26-4018-b9f3-7c27b8e26d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770164, 325)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfc6564c-e2f4-479a-a685-b0e6e5752760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369301, 325)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35f35ec2-95e6-448b-8e1c-b61e7b783060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['id4'] = pd.to_datetime(df_train['id4'], errors='coerce')\n",
    "\n",
    "df_train['id4'] = pd.to_datetime(df_train['id4'], format='%Y-%m-%d %H:%M:%S.%f', errors='coerce')\n",
    "df_test['id4'] = pd.to_datetime(df_test['id4'], format='%Y-%m-%d %H:%M:%S.%f', errors='coerce')\n",
    "df_train['id5'] = pd.to_datetime(df_train['id5'], format='%Y-%m-%d', errors='coerce')\n",
    "df_test['id5'] = pd.to_datetime(df_test['id5'], format='%Y-%m-%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c5c8a4b-1e3b-45b4-8fde-3c9c6406b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_binary_columns(df):\n",
    "    binary_cols = []\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].dropna().unique()\n",
    "        if set(unique_vals).issubset({0, 1}):\n",
    "            binary_cols.append(col)\n",
    "    \n",
    "    print(f\"✅ Found {len(binary_cols)} binary columns:\")\n",
    "    for col in binary_cols:\n",
    "        print(f\"  - {col}\")\n",
    "        \n",
    "    return binary_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2cfde45-4321-4aba-92b7-f7476575d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 90 binary columns:\n",
      "  - y\n",
      "  - f18\n",
      "  - f50\n",
      "  - f52\n",
      "  - f53\n",
      "  - f112\n",
      "  - f122\n",
      "  - f135\n",
      "  - f136\n",
      "  - f205\n",
      "  - f227\n",
      "  - f228\n",
      "  - f230\n",
      "  - f231\n",
      "  - f232\n",
      "  - f233\n",
      "  - f234\n",
      "  - f235\n",
      "  - f237\n",
      "  - f239\n",
      "  - f241\n",
      "  - f242\n",
      "  - f244\n",
      "  - f247\n",
      "  - f250\n",
      "  - f251\n",
      "  - f252\n",
      "  - f253\n",
      "  - f254\n",
      "  - f255\n",
      "  - f256\n",
      "  - f257\n",
      "  - f261\n",
      "  - f263\n",
      "  - f264\n",
      "  - f265\n",
      "  - f269\n",
      "  - f272\n",
      "  - f273\n",
      "  - f274\n",
      "  - f275\n",
      "  - f276\n",
      "  - f278\n",
      "  - f280\n",
      "  - f282\n",
      "  - f283\n",
      "  - f284\n",
      "  - f285\n",
      "  - f288\n",
      "  - f289\n",
      "  - f292\n",
      "  - f293\n",
      "  - f296\n",
      "  - f297\n",
      "  - f299\n",
      "  - f302\n",
      "  - f305\n",
      "  - f306\n",
      "  - f333\n",
      "  - f354\n",
      "  - f359\n",
      "  - f360\n",
      "  - f42_G\n",
      "  - f42_P\n",
      "  - f42_R\n",
      "  - f42_S\n",
      "  - f54_A\n",
      "  - f54_B\n",
      "  - f54_C\n",
      "  - f54_D\n",
      "  - f54_E\n",
      "  - f54_F\n",
      "  - f55_-\n",
      "  - f55_A\n",
      "  - f55_C\n",
      "  - f55_D\n",
      "  - f55_G\n",
      "  - f55_H\n",
      "  - f55_I\n",
      "  - f55_M\n",
      "  - f55_T\n",
      "  - f55_W\n",
      "  - f56_B\n",
      "  - f56_D\n",
      "  - f56_G\n",
      "  - f56_S\n",
      "  - f57_A\n",
      "  - f57_H\n",
      "  - f57_P\n",
      "  - f57_Z\n"
     ]
    }
   ],
   "source": [
    "binary_columns = find_binary_columns(df_train)\n",
    "\n",
    "# Step 2: Select non-binary columns\n",
    "non_binary_columns = [col for col in df_train.columns if col not in binary_columns]\n",
    "extra_cols = [f\"f{i}\" for i in range(226, 310) if f\"f{i}\" in df_train.columns]\n",
    "\n",
    "# Step 3: Combine both lists\n",
    "final_cols_to_exclude = binary_columns + extra_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7893c158-4577-4d8b-9463-95ec5b8b52d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['f292'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a50f3059-643b-47dd-85d3-1052907873bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify columns to drop from train\n",
    "# threshold = 0.995\n",
    "# drop_cols = df_train.columns[df_train.isna().mean() > threshold]\n",
    "\n",
    "# # Drop from both train and test\n",
    "# df_train = df_train.drop(columns=drop_cols)\n",
    "# df_test = df_test.drop(columns=drop_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a76c9-f71b-4a1f-bcaa-e8b38ca13c71",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa040c0-f064-4ba7-a1fc-1b9a67fa4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_features=pd.read_csv('event_features.csv')\n",
    "offer_features=pd.read_csv('offer_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c68908d-3df7-4736-a591-85a99d0684e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_features=pd.read_csv('transaction_features.csv')\n",
    "# Merge df_train with transaction_features using 'id3'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55d8243d-e66e-4fac-b596-36cae280504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id2</th>\n",
       "      <th>f367_sum</th>\n",
       "      <th>f367_mean</th>\n",
       "      <th>f367_std</th>\n",
       "      <th>f367_max</th>\n",
       "      <th>f367_min</th>\n",
       "      <th>signed_amount_sum</th>\n",
       "      <th>signed_amount_mean</th>\n",
       "      <th>f368_nunique</th>\n",
       "      <th>f374_nunique</th>\n",
       "      <th>id8_nunique</th>\n",
       "      <th>datetime_count</th>\n",
       "      <th>datetime_&lt;lambda_0&gt;</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>id8</th>\n",
       "      <th>id3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>11148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>556241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>96003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>547394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>731777.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id2  f367_sum   f367_mean    f367_std  f367_max  f367_min  \\\n",
       "0  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "1  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "2  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "3  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "4  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "\n",
       "   signed_amount_sum  signed_amount_mean  f368_nunique  f374_nunique  \\\n",
       "0                0.0                 0.0             1             6   \n",
       "1                0.0                 0.0             1             6   \n",
       "2                0.0                 0.0             1             6   \n",
       "3                0.0                 0.0             1             6   \n",
       "4                0.0                 0.0             1             6   \n",
       "\n",
       "   id8_nunique  datetime_count  datetime_<lambda_0>  afternoon  evening  \\\n",
       "0            7              12                    0          1        0   \n",
       "1            7              12                    0          1        0   \n",
       "2            7              12                    0          1        0   \n",
       "3            7              12                    0          1        0   \n",
       "4            7              12                    0          1        0   \n",
       "\n",
       "   morning  night  industry_code         id8       id3  \n",
       "0        4      7     59420000.0  59420000.0   11148.0  \n",
       "1        4      7     59420000.0  59420000.0  556241.0  \n",
       "2        4      7     59420000.0  59420000.0   96003.0  \n",
       "3        4      7     59420000.0  59420000.0  547394.0  \n",
       "4        4      7     59420000.0  59420000.0  731777.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcfca82e-b5c3-4672-bc46-ab061ba655ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_features['id8'] = transaction_features['id8'].astype(str)\n",
    "offer_features['id8'] = offer_features['id8'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35011123-af45-47fa-b528-91a1738ef8b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 27.6 GiB for an array with shape (3704576896,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m merged_df = pd.merge(transaction_features, offer_features, on=\u001b[33m'\u001b[39m\u001b[33mid8\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\prateek\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    170\u001b[39m     op = _MergeOperation(\n\u001b[32m    171\u001b[39m         left_df,\n\u001b[32m    172\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m         validate=validate,\n\u001b[32m    183\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\prateek\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:886\u001b[39m, in \u001b[36m_MergeOperation.get_result\u001b[39m\u001b[34m(self, copy)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.indicator:\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right = \u001b[38;5;28mself\u001b[39m._indicator_pre_merge(\u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right)\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m join_index, left_indexer, right_indexer = \u001b[38;5;28mself\u001b[39m._get_join_info()\n\u001b[32m    888\u001b[39m result = \u001b[38;5;28mself\u001b[39m._reindex_and_concat(\n\u001b[32m    889\u001b[39m     join_index, left_indexer, right_indexer, copy=copy\n\u001b[32m    890\u001b[39m )\n\u001b[32m    891\u001b[39m result = result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[38;5;28mself\u001b[39m._merge_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\prateek\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1151\u001b[39m, in \u001b[36m_MergeOperation._get_join_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1147\u001b[39m     join_index, right_indexer, left_indexer = _left_join_on_index(\n\u001b[32m   1148\u001b[39m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m.right_join_keys, sort=\u001b[38;5;28mself\u001b[39m.sort\n\u001b[32m   1149\u001b[39m     )\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1151\u001b[39m     (left_indexer, right_indexer) = \u001b[38;5;28mself\u001b[39m._get_join_indexers()\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.right_index:\n\u001b[32m   1154\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.left) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\prateek\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1125\u001b[39m, in \u001b[36m_MergeOperation._get_join_indexers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.how != \u001b[33m\"\u001b[39m\u001b[33masof\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m get_join_indexers(\n\u001b[32m   1126\u001b[39m     \u001b[38;5;28mself\u001b[39m.left_join_keys, \u001b[38;5;28mself\u001b[39m.right_join_keys, sort=\u001b[38;5;28mself\u001b[39m.sort, how=\u001b[38;5;28mself\u001b[39m.how\n\u001b[32m   1127\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\prateek\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1759\u001b[39m, in \u001b[36mget_join_indexers\u001b[39m\u001b[34m(left_keys, right_keys, sort, how)\u001b[39m\n\u001b[32m   1757\u001b[39m     _, lidx, ridx = left.join(right, how=how, return_indexers=\u001b[38;5;28;01mTrue\u001b[39;00m, sort=sort)\n\u001b[32m   1758\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1759\u001b[39m     lidx, ridx = get_join_indexers_non_unique(\n\u001b[32m   1760\u001b[39m         left._values, right._values, sort, how\n\u001b[32m   1761\u001b[39m     )\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(lidx, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[32m   1764\u001b[39m     lidx = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\prateek\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1795\u001b[39m, in \u001b[36mget_join_indexers_non_unique\u001b[39m\u001b[34m(left, right, sort, how)\u001b[39m\n\u001b[32m   1793\u001b[39m lkey, rkey, count = _factorize_keys(left, right, sort=sort)\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m how == \u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1795\u001b[39m     lidx, ridx = libjoin.left_outer_join(lkey, rkey, count, sort=sort)\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m how == \u001b[33m\"\u001b[39m\u001b[33mright\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1797\u001b[39m     ridx, lidx = libjoin.left_outer_join(rkey, lkey, count, sort=sort)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mjoin.pyx:117\u001b[39m, in \u001b[36mpandas._libs.join.left_outer_join\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 27.6 GiB for an array with shape (3704576896,) and data type int64"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(transaction_features, offer_features, on='id8', how='left')\n",
    "new_merge = pd.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a7cb3f4-b656-408d-a9a1-f87b82070a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['id3'] = df_train['id3'].astype(str)\n",
    "offer_features['id3'] = offer_features['id3'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe0fa5fe-a9ca-4659-93fb-65d2641929d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(offer_features, on='id3', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1b8749e-f692-4a72-8447-9cc3de94202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.merge(offer_features, on='id3', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30c90c55-1ffa-4ac8-bb8e-53105c9b7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['id3'] = df_train['id3'].astype(str)\n",
    "event_features['id3'] = event_features['id3'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f5d93c8-8bfe-47cc-85d3-a4353594d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(event_features, on='id3', how='left')\n",
    "df_test = df_test.merge(event_features, on='id3', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a344e0c-2b4d-4ed9-9c9c-2c8b1d8f7b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id2</th>\n",
       "      <th>f367_sum</th>\n",
       "      <th>f367_mean</th>\n",
       "      <th>f367_std</th>\n",
       "      <th>f367_max</th>\n",
       "      <th>f367_min</th>\n",
       "      <th>signed_amount_sum</th>\n",
       "      <th>signed_amount_mean</th>\n",
       "      <th>f368_nunique</th>\n",
       "      <th>f374_nunique</th>\n",
       "      <th>id8_nunique</th>\n",
       "      <th>datetime_count</th>\n",
       "      <th>datetime_&lt;lambda_0&gt;</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>id8</th>\n",
       "      <th>id3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>11148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>556241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>96003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>547394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000010</td>\n",
       "      <td>1988.86</td>\n",
       "      <td>165.738333</td>\n",
       "      <td>229.815205</td>\n",
       "      <td>625.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>59420000.0</td>\n",
       "      <td>731777.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id2  f367_sum   f367_mean    f367_std  f367_max  f367_min  \\\n",
       "0  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "1  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "2  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "3  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "4  2000010   1988.86  165.738333  229.815205    625.85       1.0   \n",
       "\n",
       "   signed_amount_sum  signed_amount_mean  f368_nunique  f374_nunique  \\\n",
       "0                0.0                 0.0             1             6   \n",
       "1                0.0                 0.0             1             6   \n",
       "2                0.0                 0.0             1             6   \n",
       "3                0.0                 0.0             1             6   \n",
       "4                0.0                 0.0             1             6   \n",
       "\n",
       "   id8_nunique  datetime_count  datetime_<lambda_0>  afternoon  evening  \\\n",
       "0            7              12                    0          1        0   \n",
       "1            7              12                    0          1        0   \n",
       "2            7              12                    0          1        0   \n",
       "3            7              12                    0          1        0   \n",
       "4            7              12                    0          1        0   \n",
       "\n",
       "   morning  night  industry_code         id8       id3  \n",
       "0        4      7     59420000.0  59420000.0   11148.0  \n",
       "1        4      7     59420000.0  59420000.0  556241.0  \n",
       "2        4      7     59420000.0  59420000.0   96003.0  \n",
       "3        4      7     59420000.0  59420000.0  547394.0  \n",
       "4        4      7     59420000.0  59420000.0  731777.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "832969bc-5621-4961-be30-1193f40286e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['id3'] = df_train['id3'].astype(str)\n",
    "transaction_features['id3'] = transaction_features['id3'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c1e0d11-0ea7-4b30-9438-3947dbe23d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(transaction_features, on='id3', how='left')\n",
    "df_test = df_test.merge(transaction_features, on='id3', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a58adc56-27ed-488a-99d4-28e6a7dc68de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2_x</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>y</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>...</th>\n",
       "      <th>f374_nunique</th>\n",
       "      <th>id8_nunique</th>\n",
       "      <th>datetime_count</th>\n",
       "      <th>datetime_&lt;lambda_0&gt;</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>id8_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1366776_189706075_16-23_2023-11-02 22:22:00.042</td>\n",
       "      <td>1366776</td>\n",
       "      <td>189706075</td>\n",
       "      <td>2023-11-02 22:22:00.042</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366776_89227_16-23_2023-11-01 23:51:24.999</td>\n",
       "      <td>1366776</td>\n",
       "      <td>89227</td>\n",
       "      <td>2023-11-01 23:51:24.999</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1366776_35046_16-23_2023-11-01 00:30:59.797</td>\n",
       "      <td>1366776</td>\n",
       "      <td>35046</td>\n",
       "      <td>2023-11-01 00:30:59.797</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1366776_6275451_16-23_2023-11-02 22:21:32.261</td>\n",
       "      <td>1366776</td>\n",
       "      <td>6275451</td>\n",
       "      <td>2023-11-02 22:21:32.261</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1366776_78053_16-23_2023-11-02 22:21:34.799</td>\n",
       "      <td>1366776</td>\n",
       "      <td>78053</td>\n",
       "      <td>2023-11-02 22:21:34.799</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               id1    id2_x        id3  \\\n",
       "0  1366776_189706075_16-23_2023-11-02 22:22:00.042  1366776  189706075   \n",
       "1      1366776_89227_16-23_2023-11-01 23:51:24.999  1366776      89227   \n",
       "2      1366776_35046_16-23_2023-11-01 00:30:59.797  1366776      35046   \n",
       "3    1366776_6275451_16-23_2023-11-02 22:21:32.261  1366776    6275451   \n",
       "4      1366776_78053_16-23_2023-11-02 22:21:34.799  1366776      78053   \n",
       "\n",
       "                      id4        id5  y   f1  f2  f3  f4  ...  f374_nunique  \\\n",
       "0 2023-11-02 22:22:00.042 2023-11-02  0  1.0 NaN NaN NaN  ...           NaN   \n",
       "1 2023-11-01 23:51:24.999 2023-11-01  0  1.0 NaN NaN NaN  ...           NaN   \n",
       "2 2023-11-01 00:30:59.797 2023-11-01  0  1.0 NaN NaN NaN  ...           NaN   \n",
       "3 2023-11-02 22:21:32.261 2023-11-02  0  1.0 NaN NaN NaN  ...           NaN   \n",
       "4 2023-11-02 22:21:34.799 2023-11-02  0  1.0 NaN NaN NaN  ...           NaN   \n",
       "\n",
       "   id8_nunique  datetime_count  datetime_<lambda_0>  afternoon  evening  \\\n",
       "0          NaN             NaN                  NaN        NaN      NaN   \n",
       "1          NaN             NaN                  NaN        NaN      NaN   \n",
       "2          NaN             NaN                  NaN        NaN      NaN   \n",
       "3          NaN             NaN                  NaN        NaN      NaN   \n",
       "4          NaN             NaN                  NaN        NaN      NaN   \n",
       "\n",
       "   morning  night  industry_code  id8_y  \n",
       "0      NaN    NaN            NaN    NaN  \n",
       "1      NaN    NaN            NaN    NaN  \n",
       "2      NaN    NaN            NaN    NaN  \n",
       "3      NaN    NaN            NaN    NaN  \n",
       "4      NaN    NaN            NaN    NaN  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc80e8dd-107d-4219-96c2-59ac45e50cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['afternoon'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "348ba02b-0e34-4926-aa16-aef2bd88b758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91637\\AppData\\Local\\Temp\\ipykernel_37096\\3161309805.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns:\n",
    "    if col not in binary_columns and df_train[col].isna().any():\n",
    "        df_train[col].fillna(df_train[col].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f4ce8ce-03fc-42f7-ba08-cc8a828c7447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91637\\AppData\\Local\\Temp\\ipykernel_37096\\4209636367.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for col in df_test.columns:\n",
    "    if col not in binary_columns and df_test[col].isna().any():\n",
    "        if col in df_train.columns:\n",
    "            median_val = df_train[col].median()\n",
    "            df_test[col].fillna(median_val, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6669a72c-9016-4207-8849-2a53ad3e8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['id3'] = df_train['id3'].astype(str)\n",
    "# transaction_features['id3'] = transaction_features['id3'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8413c147-1376-4819-a0fc-cac561f817c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.merge(transaction_features, on='id3', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef94d715-9bf1-472b-8910-ef03955fb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = df_test.merge(transaction_features, on='id3', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af43b321-c8bb-4c81-966d-f5e1cc362596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 770164 entries, 0 to 770163\n",
      "Columns: 492 entries, id1 to clicks_short\n",
      "dtypes: datetime64[ns](2), float64(448), int64(39), object(3)\n",
      "memory usage: 2.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a4f28bc-eb59-4e99-b031-6bd3035dac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 369301 entries, 0 to 369300\n",
      "Columns: 492 entries, id1 to clicks_short\n",
      "dtypes: datetime64[ns](2), float64(457), int64(30), object(3)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d64b1ee-f244-4d52-9e2b-fa4b25c70a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>y</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>...</th>\n",
       "      <th>num_unique_users</th>\n",
       "      <th>num_users_clicked</th>\n",
       "      <th>min_click_delay</th>\n",
       "      <th>max_click_delay</th>\n",
       "      <th>std_click_delay</th>\n",
       "      <th>clicks_immediate</th>\n",
       "      <th>clicks_long</th>\n",
       "      <th>clicks_medium</th>\n",
       "      <th>clicks_no_click</th>\n",
       "      <th>clicks_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1366776_189706075_16-23_2023-11-02 22:22:00.042</td>\n",
       "      <td>1366776</td>\n",
       "      <td>189706075</td>\n",
       "      <td>2023-11-02 22:22:00.042</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10912</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>2405.285562</td>\n",
       "      <td>134.504541</td>\n",
       "      <td>916</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>17146</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366776_89227_16-23_2023-11-01 23:51:24.999</td>\n",
       "      <td>1366776</td>\n",
       "      <td>89227</td>\n",
       "      <td>2023-11-01 23:51:24.999</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11788</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>3129.141752</td>\n",
       "      <td>180.042932</td>\n",
       "      <td>774</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>19814</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1366776_35046_16-23_2023-11-01 00:30:59.797</td>\n",
       "      <td>1366776</td>\n",
       "      <td>35046</td>\n",
       "      <td>2023-11-01 00:30:59.797</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10976</td>\n",
       "      <td>752.0</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2533.306814</td>\n",
       "      <td>169.449032</td>\n",
       "      <td>592</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>17537</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1366776_6275451_16-23_2023-11-02 22:21:32.261</td>\n",
       "      <td>1366776</td>\n",
       "      <td>6275451</td>\n",
       "      <td>2023-11-02 22:21:32.261</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10840</td>\n",
       "      <td>759.0</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>2948.896710</td>\n",
       "      <td>194.759984</td>\n",
       "      <td>583</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>17241</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1366776_78053_16-23_2023-11-02 22:21:34.799</td>\n",
       "      <td>1366776</td>\n",
       "      <td>78053</td>\n",
       "      <td>2023-11-02 22:21:34.799</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11090</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>2648.256892</td>\n",
       "      <td>185.241993</td>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>17644</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 492 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               id1      id2        id3  \\\n",
       "0  1366776_189706075_16-23_2023-11-02 22:22:00.042  1366776  189706075   \n",
       "1      1366776_89227_16-23_2023-11-01 23:51:24.999  1366776      89227   \n",
       "2      1366776_35046_16-23_2023-11-01 00:30:59.797  1366776      35046   \n",
       "3    1366776_6275451_16-23_2023-11-02 22:21:32.261  1366776    6275451   \n",
       "4      1366776_78053_16-23_2023-11-02 22:21:34.799  1366776      78053   \n",
       "\n",
       "                      id4        id5  y   f1    f2    f3    f4  ...  \\\n",
       "0 2023-11-02 22:22:00.042 2023-11-02  0  1.0  31.0  31.0  40.0  ...   \n",
       "1 2023-11-01 23:51:24.999 2023-11-01  0  1.0  31.0  31.0  40.0  ...   \n",
       "2 2023-11-01 00:30:59.797 2023-11-01  0  1.0  31.0  31.0  40.0  ...   \n",
       "3 2023-11-02 22:21:32.261 2023-11-02  0  1.0  31.0  31.0  40.0  ...   \n",
       "4 2023-11-02 22:21:34.799 2023-11-02  0  1.0  31.0  31.0  40.0  ...   \n",
       "\n",
       "   num_unique_users  num_users_clicked  min_click_delay  max_click_delay  \\\n",
       "0             10912             1083.0         0.002516      2405.285562   \n",
       "1             11788              948.0         0.000413      3129.141752   \n",
       "2             10976              752.0         0.002397      2533.306814   \n",
       "3             10840              759.0         0.005870      2948.896710   \n",
       "4             11090              774.0         0.012640      2648.256892   \n",
       "\n",
       "   std_click_delay  clicks_immediate  clicks_long  clicks_medium  \\\n",
       "0       134.504541               916            2             31   \n",
       "1       180.042932               774            3             37   \n",
       "2       169.449032               592            2             39   \n",
       "3       194.759984               583            3             33   \n",
       "4       185.241993               608            2             37   \n",
       "\n",
       "   clicks_no_click  clicks_short  \n",
       "0            17146           143  \n",
       "1            19814           152  \n",
       "2            17537           126  \n",
       "3            17241           152  \n",
       "4            17644           137  \n",
       "\n",
       "[5 rows x 492 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d8aa86b-3db0-41b0-9b5a-b8ec37d42448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Columns in test but not in train (2):\n",
      "  - f17\n",
      "  - f80\n"
     ]
    }
   ],
   "source": [
    "diff_cols = [col for col in df_test.columns if col not in df_train.columns]\n",
    "\n",
    "print(f\"🧪 Columns in test but not in train ({len(diff_cols)}):\")\n",
    "for col in diff_cols:\n",
    "    print(f\"  - {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4bb5048-53f1-4522-9565-9321aa2f2d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎓 Columns in train but not in test (2):\n",
      "  - y\n",
      "  - f71\n"
     ]
    }
   ],
   "source": [
    "extra_train_cols = [col for col in df_train.columns if col not in df_test.columns]\n",
    "\n",
    "print(f\"🎓 Columns in train but not in test ({len(extra_train_cols)}):\")\n",
    "for col in extra_train_cols:\n",
    "    print(f\"  - {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f9461f0-1c93-421e-83f6-54f7d1571f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.drop(columns=['f17','f80'])\n",
    "df_train=df_train.drop(columns=['f71'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcd79400-a026-4e04-9c48-9bf0bb945336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 770164 entries, 0 to 770163\n",
      "Columns: 491 entries, id1 to clicks_short\n",
      "dtypes: datetime64[ns](2), float64(447), int64(39), object(3)\n",
      "memory usage: 2.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7931e58-e943-451a-93dd-5694fc8c95ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 369301 entries, 0 to 369300\n",
      "Columns: 490 entries, id1 to clicks_short\n",
      "dtypes: datetime64[ns](2), float64(455), int64(30), object(3)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01858753-c0dc-446a-8007-062c86568d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train=df_train.fillna(0)\n",
    "# df_test=df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77c24c05-3c14-4f9d-b6c7-f9dd88f0174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import lightgbm as lgb\n",
    "# from lightgbm import early_stopping, log_evaluation\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2802f9e9-567e-4116-937a-cfb2a992fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_column_names(df):\n",
    "#     df.columns = df.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "#     return df\n",
    "\n",
    "# df_train = clean_column_names(df_train)\n",
    "# df_test = clean_column_names(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec585afb-8482-434b-8ec7-114e5b05481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Prepare data\n",
    "# exclude_cols = ['y', 'id3', 'id4', 'id5', 'id1']  # keep id2 for grouping\n",
    "# features = [col for col in df_train.columns if col not in exclude_cols]\n",
    "\n",
    "# X = df_train[features]\n",
    "# y = df_train['y']\n",
    "# groups = df_train['id2']  # for ranking group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fb981f9-4b79-447f-86eb-6eed854122fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Split data\n",
    "# X_train, X_val, y_train, y_val, groups_train, groups_val = train_test_split(\n",
    "#     X, y, groups, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04cc7120-6b66-4803-8915-b4ac3fee486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.copy()\n",
    "# X_val = X_val.copy()\n",
    "# X_train = X_train.drop(columns=['id2'], errors='ignore')\n",
    "# X_val = X_val.drop(columns=['id2'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b470fb04-d830-446b-bc9a-4314f9582b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_train_sizes = groups_train.groupby(groups_train).size().tolist()\n",
    "# group_val_sizes = groups_val.groupby(groups_val).size().tolist()\n",
    "\n",
    "# lgb_train = lgb.Dataset(X_train, label=y_train, group=group_train_sizes)\n",
    "# lgb_val = lgb.Dataset(X_val, label=y_val, group=group_val_sizes, reference=lgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6d7e665-8259-4481-8e3f-5834d588dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# import lightgbm as lgb\n",
    "# import numpy as np\n",
    "\n",
    "# params = {\n",
    "#     'learning_rate': 0.03,\n",
    "#     'num_leaves': 32,          # was 16\n",
    "#     'max_depth': 6,            # was 4\n",
    "#     'min_child_samples': 100,  # was 300\n",
    "#     'feature_fraction': 0.8,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'bagging_freq': 5,\n",
    "#     'lambda_l1': 1,\n",
    "#     'lambda_l2': 1,\n",
    "#     'n_estimators': 5000,\n",
    "#     'objective': 'lambdarank',\n",
    "#     'metric': 'auc',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'verbosity': -1,\n",
    "#     'n_jobs': -1\n",
    "# }\n",
    "\n",
    "# # ✅ Define selected features (manually, no SelectKBest)\n",
    "\n",
    "\n",
    "# kf = GroupKFold(n_splits=5)\n",
    "# fold = 1\n",
    "# auc_scores = []\n",
    "\n",
    "# for train_idx, val_idx in kf.split(X, y, groups):\n",
    "#     print(f\"\\n📂 Fold {fold}\")\n",
    "    \n",
    "#     X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
    "#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#     # Extract and drop group column\n",
    "#     group_train = X_train.pop('id2')\n",
    "#     group_val = X_val.pop('id2')\n",
    "\n",
    "#     # # Feature Selection\n",
    "#     # selector = SelectKBest(score_func=f_classif, k=250)\n",
    "#     # selector.fit(X_train, y_train)\n",
    "\n",
    "#     # X_train_selected = selector.transform(X_train)\n",
    "#     # X_val_selected = selector.transform(X_val)\n",
    "#     # selected_features = X_train.columns[selector.get_support()]\n",
    "\n",
    "#     # Convert back to DataFrame\n",
    "#     # X_train = pd.DataFrame(X_train_selected, columns=selected_features, index=X_train.index)\n",
    "#     # X_val = pd.DataFrame(X_val_selected, columns=selected_features, index=X_val.index)\n",
    "\n",
    "#     # Group sizes\n",
    "#     group_train_sizes = group_train.groupby(group_train).size().tolist()\n",
    "#     group_val_sizes = group_val.groupby(group_val).size().tolist()\n",
    "\n",
    "#     lgb_train = lgb.Dataset(X_train, label=y_train, group=group_train_sizes)\n",
    "#     lgb_val = lgb.Dataset(X_val, label=y_val, group=group_val_sizes, reference=lgb_train)\n",
    "\n",
    "#     model = lgb.train(\n",
    "#         params,\n",
    "#         lgb_train,\n",
    "#         valid_sets=[lgb_train, lgb_val],\n",
    "#         valid_names=['train', 'valid'],\n",
    "#         num_boost_round=500,\n",
    "#         callbacks=[\n",
    "#             early_stopping(stopping_rounds=50),\n",
    "#             log_evaluation(period=50)\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     auc = model.best_score['valid']['auc']\n",
    "#     auc_scores.append(auc)\n",
    "#     print(f\"✅ Fold {fold} AUC: {auc:.5f}\")\n",
    "#     fold += 1\n",
    "\n",
    "# print(f\"\\n📊 Average AUC over folds: {np.mean(auc_scores):.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46a0661c-058f-414c-a979-dcdc53bee5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retain ID columns separately for later use in submission\n",
    "# id_cols = df_test[['id1', 'id2', 'id3', 'id5']].copy()\n",
    "\n",
    "# # Prepare test features by dropping ID columns\n",
    "# # Get list of features that exist in both df_test and selected_features\n",
    "\n",
    "# # Remove non-numeric features from selected_features\n",
    "# numeric_features = [f for f in selected_features if pd.api.types.is_numeric_dtype(df_test[f])]\n",
    "\n",
    "# # Use only numeric features for prediction\n",
    "# X_test = df_test[numeric_features]\n",
    "\n",
    "\n",
    "# # Make predictions using the trained model\n",
    "# y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# # Create a final submission dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3746563-8f3a-4951-96d0-c6a7e796ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Original predictions\n",
    "# # test_preds = model.predict(X_test)\n",
    "\n",
    "# # Scale to [0, 1]\n",
    "# scaler = MinMaxScaler()\n",
    "# test_preds_scaled = scaler.fit_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "# # Add to submission\n",
    "# submission = id_cols.copy()  # id1, id2, id3, id5 already stored\n",
    "# submission['pred'] = test_preds_scaled\n",
    "\n",
    "# # Save CSV\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"✅ Scaled submission saved as 'submission.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4a4a775-3399-40b3-8777-24c61d3a6ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:51:41,556] A new study created in memory with name: no-name-284c1cca-2b43-454e-a03d-35385a9f1fbb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.928034\tvalid's map@2: 0.928357\tvalid's map@3: 0.928586\tvalid's map@4: 0.929252\tvalid's map@5: 0.930115\n",
      "[200]\tvalid's map@1: 0.929108\tvalid's map@2: 0.929753\tvalid's map@3: 0.930198\tvalid's map@4: 0.930943\tvalid's map@5: 0.931463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:52:02,739] Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 0.022737040030900227, 'num_leaves': 52, 'max_depth': 4, 'min_child_samples': 66, 'lambda_l1': 3.1204870035499646, 'lambda_l2': 2.4504408908372417, 'feature_fraction': 0.8766530247173325, 'bagging_fraction': 0.9052181436606378, 'bagging_freq': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[167]\tvalid's map@1: 0.929968\tvalid's map@2: 0.93029\tvalid's map@3: 0.930481\tvalid's map@4: 0.931166\tvalid's map@5: 0.931715\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.930827\tvalid's map@2: 0.931391\tvalid's map@3: 0.931561\tvalid's map@4: 0.932451\tvalid's map@5: 0.932972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:52:15,326] Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 0.061895847989666464, 'num_leaves': 22, 'max_depth': 9, 'min_child_samples': 59, 'lambda_l1': 3.641850337475792, 'lambda_l2': 4.834610978801282, 'feature_fraction': 0.9093203753448413, 'bagging_fraction': 0.7386127190869898, 'bagging_freq': 10}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid's map@1: 0.931901\tvalid's map@2: 0.931686\tvalid's map@3: 0.931979\tvalid's map@4: 0.932916\tvalid's map@5: 0.933429\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.931257\tvalid's map@2: 0.930666\tvalid's map@3: 0.931245\tvalid's map@4: 0.932038\tvalid's map@5: 0.932507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:52:22,540] Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 0.08159880697562191, 'num_leaves': 18, 'max_depth': 12, 'min_child_samples': 45, 'lambda_l1': 2.597566485550483, 'lambda_l2': 3.2624004312225963, 'feature_fraction': 0.9478222871393936, 'bagging_fraction': 0.5146420313628557, 'bagging_freq': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid's map@1: 0.931472\tvalid's map@2: 0.930908\tvalid's map@3: 0.931457\tvalid's map@4: 0.932212\tvalid's map@5: 0.932736\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.93072\tvalid's map@2: 0.931203\tvalid's map@3: 0.931665\tvalid's map@4: 0.932578\tvalid's map@5: 0.933071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:52:38,269] Trial 3 finished with value: 0.0 and parameters: {'learning_rate': 0.0825158177530294, 'num_leaves': 53, 'max_depth': 8, 'min_child_samples': 74, 'lambda_l1': 3.79268083719234, 'lambda_l2': 0.6985467732715039, 'feature_fraction': 0.6396780841365175, 'bagging_fraction': 0.7919838249783331, 'bagging_freq': 9}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid's map@1: 0.932116\tvalid's map@2: 0.932197\tvalid's map@3: 0.932489\tvalid's map@4: 0.933128\tvalid's map@5: 0.933684\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.931149\tvalid's map@2: 0.931686\tvalid's map@3: 0.931919\tvalid's map@4: 0.932572\tvalid's map@5: 0.932866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:52:49,771] Trial 4 finished with value: 0.0 and parameters: {'learning_rate': 0.05393421178183967, 'num_leaves': 51, 'max_depth': 7, 'min_child_samples': 57, 'lambda_l1': 1.6603894855509993, 'lambda_l2': 3.408014168495405, 'feature_fraction': 0.8514212741891469, 'bagging_fraction': 0.6088156452201952, 'bagging_freq': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid's map@1: 0.931042\tvalid's map@2: 0.931713\tvalid's map@3: 0.931952\tvalid's map@4: 0.932597\tvalid's map@5: 0.932825\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.929001\tvalid's map@2: 0.929028\tvalid's map@3: 0.929652\tvalid's map@4: 0.930609\tvalid's map@5: 0.931068\n",
      "[200]\tvalid's map@1: 0.93072\tvalid's map@2: 0.930317\tvalid's map@3: 0.931042\tvalid's map@4: 0.931972\tvalid's map@5: 0.932423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:53:11,059] Trial 5 finished with value: 0.0 and parameters: {'learning_rate': 0.02752386279654539, 'num_leaves': 17, 'max_depth': 10, 'min_child_samples': 68, 'lambda_l1': 1.163062897592511, 'lambda_l2': 3.3645880401717694, 'feature_fraction': 0.6755851277262261, 'bagging_fraction': 0.9291300357889221, 'bagging_freq': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[246]\tvalid's map@1: 0.931794\tvalid's map@2: 0.931284\tvalid's map@3: 0.931603\tvalid's map@4: 0.932403\tvalid's map@5: 0.93291\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.931579\tvalid's map@2: 0.930747\tvalid's map@3: 0.931227\tvalid's map@4: 0.932224\tvalid's map@5: 0.932662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:53:22,089] Trial 6 finished with value: 0.0 and parameters: {'learning_rate': 0.08306522087135637, 'num_leaves': 18, 'max_depth': 6, 'min_child_samples': 72, 'lambda_l1': 2.476873293436638, 'lambda_l2': 4.336259207764764, 'feature_fraction': 0.8893497763286417, 'bagging_fraction': 0.6194753862552239, 'bagging_freq': 10}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[123]\tvalid's map@1: 0.932331\tvalid's map@2: 0.931284\tvalid's map@3: 0.931842\tvalid's map@4: 0.93278\tvalid's map@5: 0.933185\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:53:29,895] Trial 7 finished with value: 0.0 and parameters: {'learning_rate': 0.022620236825388267, 'num_leaves': 38, 'max_depth': 11, 'min_child_samples': 86, 'lambda_l1': 3.6982910892653234, 'lambda_l2': 0.057155022378611586, 'feature_fraction': 0.9612760596521275, 'bagging_fraction': 0.9362740667209568, 'bagging_freq': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid's map@1: 0.929001\tvalid's map@2: 0.928034\tvalid's map@3: 0.9277\tvalid's map@4: 0.928739\tvalid's map@5: 0.929509\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:53:35,994] Trial 8 finished with value: 0.0 and parameters: {'learning_rate': 0.05299720234249806, 'num_leaves': 28, 'max_depth': 10, 'min_child_samples': 38, 'lambda_l1': 4.450783007141889, 'lambda_l2': 3.584476261828573, 'feature_fraction': 0.8113120598952432, 'bagging_fraction': 0.5616199424174214, 'bagging_freq': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid's map@1: 0.929753\tvalid's map@2: 0.929404\tvalid's map@3: 0.929207\tvalid's map@4: 0.929849\tvalid's map@5: 0.930777\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:53:47,577] Trial 9 finished with value: 0.0 and parameters: {'learning_rate': 0.01806080322838683, 'num_leaves': 64, 'max_depth': 12, 'min_child_samples': 25, 'lambda_l1': 2.5226648211406855, 'lambda_l2': 2.8556773000451807, 'feature_fraction': 0.9766203563411586, 'bagging_fraction': 0.8075553061884712, 'bagging_freq': 2}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid's map@1: 0.928464\tvalid's map@2: 0.929538\tvalid's map@3: 0.929702\tvalid's map@4: 0.930544\tvalid's map@5: 0.931226\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.929108\tvalid's map@2: 0.92935\tvalid's map@3: 0.929538\tvalid's map@4: 0.930479\tvalid's map@5: 0.931168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:54:01,504] Trial 10 finished with value: 0.0 and parameters: {'learning_rate': 0.03788429596237933, 'num_leaves': 46, 'max_depth': 4, 'min_child_samples': 100, 'lambda_l1': 0.05120551295241693, 'lambda_l2': 1.7123274463927682, 'feature_fraction': 0.5076262279683896, 'bagging_fraction': 0.975913533504481, 'bagging_freq': 1}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[126]\tvalid's map@1: 0.92986\tvalid's map@2: 0.929699\tvalid's map@3: 0.930275\tvalid's map@4: 0.931081\tvalid's map@5: 0.931742\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.930934\tvalid's map@2: 0.931122\tvalid's map@3: 0.931958\tvalid's map@4: 0.932492\tvalid's map@5: 0.933131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:54:11,674] Trial 11 finished with value: 0.0 and parameters: {'learning_rate': 0.0632267413133311, 'num_leaves': 31, 'max_depth': 5, 'min_child_samples': 53, 'lambda_l1': 4.846957471550565, 'lambda_l2': 1.8123538177505036, 'feature_fraction': 0.7771337380508383, 'bagging_fraction': 0.7103372001672841, 'bagging_freq': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid's map@1: 0.931257\tvalid's map@2: 0.93123\tvalid's map@3: 0.931916\tvalid's map@4: 0.932499\tvalid's map@5: 0.933111\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.932009\tvalid's map@2: 0.932089\tvalid's map@3: 0.932185\tvalid's map@4: 0.932989\tvalid's map@5: 0.933466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:54:30,494] Trial 12 finished with value: 0.0 and parameters: {'learning_rate': 0.06748696959050098, 'num_leaves': 62, 'max_depth': 9, 'min_child_samples': 83, 'lambda_l1': 3.405338547606521, 'lambda_l2': 4.330759601431013, 'feature_fraction': 0.8926838223694704, 'bagging_fraction': 0.8671968726306574, 'bagging_freq': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid's map@1: 0.932438\tvalid's map@2: 0.932573\tvalid's map@3: 0.932746\tvalid's map@4: 0.933121\tvalid's map@5: 0.933709\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.931042\tvalid's map@2: 0.931015\tvalid's map@3: 0.931066\tvalid's map@4: 0.931991\tvalid's map@5: 0.932465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:54:45,314] Trial 13 finished with value: 0.0 and parameters: {'learning_rate': 0.03878967088854995, 'num_leaves': 40, 'max_depth': 7, 'min_child_samples': 61, 'lambda_l1': 3.1451841620273653, 'lambda_l2': 4.9046589344805, 'feature_fraction': 0.7382095952585417, 'bagging_fraction': 0.7157591398988548, 'bagging_freq': 10}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tvalid's map@1: 0.931472\tvalid's map@2: 0.93166\tvalid's map@3: 0.932056\tvalid's map@4: 0.932887\tvalid's map@5: 0.933225\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.92739\tvalid's map@2: 0.927202\tvalid's map@3: 0.927485\tvalid's map@4: 0.92819\tvalid's map@5: 0.928867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:54:55,983] Trial 14 finished with value: 0.0 and parameters: {'learning_rate': 0.010114260151341911, 'num_leaves': 28, 'max_depth': 4, 'min_child_samples': 44, 'lambda_l1': 4.17264603417855, 'lambda_l2': 2.1801312631763077, 'feature_fraction': 0.9010272809702272, 'bagging_fraction': 0.8662054407467378, 'bagging_freq': 3}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid's map@1: 0.927927\tvalid's map@2: 0.927444\tvalid's map@3: 0.927629\tvalid's map@4: 0.928322\tvalid's map@5: 0.929006\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.930075\tvalid's map@2: 0.930424\tvalid's map@3: 0.931376\tvalid's map@4: 0.932317\tvalid's map@5: 0.932772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:55:10,540] Trial 15 finished with value: 0.0 and parameters: {'learning_rate': 0.09959290694092343, 'num_leaves': 55, 'max_depth': 8, 'min_child_samples': 29, 'lambda_l1': 1.9125102651387562, 'lambda_l2': 1.195563576595457, 'feature_fraction': 0.8247068769022046, 'bagging_fraction': 0.6646996487633792, 'bagging_freq': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid's map@1: 0.930505\tvalid's map@2: 0.93123\tvalid's map@3: 0.931856\tvalid's map@4: 0.932454\tvalid's map@5: 0.932714\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.92986\tvalid's map@2: 0.9308\tvalid's map@3: 0.930854\tvalid's map@4: 0.931744\tvalid's map@5: 0.932303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:55:27,911] Trial 16 finished with value: 0.0 and parameters: {'learning_rate': 0.04026553529476752, 'num_leaves': 43, 'max_depth': 6, 'min_child_samples': 81, 'lambda_l1': 3.2159080187101385, 'lambda_l2': 2.6375261976797857, 'feature_fraction': 0.9966717957445617, 'bagging_fraction': 0.7845271063995771, 'bagging_freq': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[123]\tvalid's map@1: 0.929968\tvalid's map@2: 0.931391\tvalid's map@3: 0.931164\tvalid's map@4: 0.93201\tvalid's map@5: 0.932564\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.932223\tvalid's map@2: 0.932062\tvalid's map@3: 0.931943\tvalid's map@4: 0.933051\tvalid's map@5: 0.933455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:55:40,790] Trial 17 finished with value: 0.0 and parameters: {'learning_rate': 0.06405275054033686, 'num_leaves': 34, 'max_depth': 9, 'min_child_samples': 63, 'lambda_l1': 4.970811431200168, 'lambda_l2': 4.084314711036803, 'feature_fraction': 0.7232158449794286, 'bagging_fraction': 0.8557407627214497, 'bagging_freq': 9}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[94]\tvalid's map@1: 0.932653\tvalid's map@2: 0.932438\tvalid's map@3: 0.932125\tvalid's map@4: 0.933224\tvalid's map@5: 0.933599\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.929538\tvalid's map@2: 0.931015\tvalid's map@3: 0.931418\tvalid's map@4: 0.932112\tvalid's map@5: 0.932424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:55:55,123] Trial 18 finished with value: 0.0 and parameters: {'learning_rate': 0.04716320669356166, 'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 50, 'lambda_l1': 2.8085030416101517, 'lambda_l2': 4.957504337065923, 'feature_fraction': 0.9096901815937533, 'bagging_fraction': 0.7374262762779225, 'bagging_freq': 5}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[128]\tvalid's map@1: 0.931042\tvalid's map@2: 0.932143\tvalid's map@3: 0.93168\tvalid's map@4: 0.932556\tvalid's map@5: 0.933146\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.931794\tvalid's map@2: 0.931955\tvalid's map@3: 0.932176\tvalid's map@4: 0.932634\tvalid's map@5: 0.933258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:56:05,979] Trial 19 finished with value: 0.0 and parameters: {'learning_rate': 0.07149033873460064, 'num_leaves': 23, 'max_depth': 9, 'min_child_samples': 96, 'lambda_l1': 4.070777318408869, 'lambda_l2': 2.1906543431518486, 'feature_fraction': 0.8532407603441001, 'bagging_fraction': 0.6698439692714593, 'bagging_freq': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid's map@1: 0.932009\tvalid's map@2: 0.932035\tvalid's map@3: 0.932149\tvalid's map@4: 0.932879\tvalid's map@5: 0.933377\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.928571\tvalid's map@2: 0.92978\tvalid's map@3: 0.929657\tvalid's map@4: 0.930707\tvalid's map@5: 0.931307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:56:15,184] Trial 20 finished with value: 0.0 and parameters: {'learning_rate': 0.029746172565786284, 'num_leaves': 58, 'max_depth': 5, 'min_child_samples': 34, 'lambda_l1': 0.86523569422903, 'lambda_l2': 1.1446219919553409, 'feature_fraction': 0.5902584019584615, 'bagging_fraction': 0.9853946850565366, 'bagging_freq': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid's map@1: 0.929108\tvalid's map@2: 0.929216\tvalid's map@3: 0.929422\tvalid's map@4: 0.930062\tvalid's map@5: 0.930866\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.930183\tvalid's map@2: 0.931203\tvalid's map@3: 0.931158\tvalid's map@4: 0.93188\tvalid's map@5: 0.93228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:56:26,663] Trial 21 finished with value: 0.0 and parameters: {'learning_rate': 0.08035028291216477, 'num_leaves': 23, 'max_depth': 12, 'min_child_samples': 44, 'lambda_l1': 2.1881232819606304, 'lambda_l2': 2.88325882033042, 'feature_fraction': 0.937789860206591, 'bagging_fraction': 0.533323711898182, 'bagging_freq': 9}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid's map@1: 0.931042\tvalid's map@2: 0.931364\tvalid's map@3: 0.931603\tvalid's map@4: 0.932437\tvalid's map@5: 0.93288\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:56:34,033] Trial 22 finished with value: 0.0 and parameters: {'learning_rate': 0.09761011450063305, 'num_leaves': 20, 'max_depth': 11, 'min_child_samples': 48, 'lambda_l1': 2.8254536830495107, 'lambda_l2': 3.9464277435904362, 'feature_fraction': 0.9324469800648865, 'bagging_fraction': 0.5142925828568201, 'bagging_freq': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid's map@1: 0.93072\tvalid's map@2: 0.931257\tvalid's map@3: 0.93094\tvalid's map@4: 0.931956\tvalid's map@5: 0.932235\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid's map@1: 0.931579\tvalid's map@2: 0.930934\tvalid's map@3: 0.931167\tvalid's map@4: 0.931964\tvalid's map@5: 0.932285\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.931149\tvalid's map@2: 0.931069\tvalid's map@3: 0.931239\tvalid's map@4: 0.932321\tvalid's map@5: 0.932909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:56:44,859] Trial 23 finished with value: 0.0 and parameters: {'learning_rate': 0.07503071538466108, 'num_leaves': 24, 'max_depth': 11, 'min_child_samples': 65, 'lambda_l1': 3.5943924993676495, 'lambda_l2': 3.1036989667892922, 'feature_fraction': 0.8556192314625586, 'bagging_fraction': 0.5761166386880586, 'bagging_freq': 10}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid's map@1: 0.931257\tvalid's map@2: 0.93166\tvalid's map@3: 0.93129\tvalid's map@4: 0.932602\tvalid's map@5: 0.933108\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.931257\tvalid's map@2: 0.930532\tvalid's map@3: 0.930964\tvalid's map@4: 0.931789\tvalid's map@5: 0.932283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:56:54,269] Trial 24 finished with value: 0.0 and parameters: {'learning_rate': 0.08845831085103383, 'num_leaves': 16, 'max_depth': 10, 'min_child_samples': 58, 'lambda_l1': 2.8298073685046403, 'lambda_l2': 2.255728594474978, 'feature_fraction': 0.7974615313462294, 'bagging_fraction': 0.670407176111369, 'bagging_freq': 9}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid's map@1: 0.931364\tvalid's map@2: 0.930424\tvalid's map@3: 0.93106\tvalid's map@4: 0.93183\tvalid's map@5: 0.932325\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.932653\tvalid's map@2: 0.932062\tvalid's map@3: 0.932179\tvalid's map@4: 0.932821\tvalid's map@5: 0.933488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:57:04,518] Trial 25 finished with value: 0.0 and parameters: {'learning_rate': 0.09019291723251008, 'num_leaves': 35, 'max_depth': 8, 'min_child_samples': 42, 'lambda_l1': 1.5119927099053827, 'lambda_l2': 1.6178824902432778, 'feature_fraction': 0.9502049040462256, 'bagging_fraction': 0.9113301465348269, 'bagging_freq': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid's map@1: 0.931794\tvalid's map@2: 0.931955\tvalid's map@3: 0.932173\tvalid's map@4: 0.933015\tvalid's map@5: 0.933483\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.930934\tvalid's map@2: 0.931552\tvalid's map@3: 0.93163\tvalid's map@4: 0.93226\tvalid's map@5: 0.932837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:57:18,348] Trial 26 finished with value: 0.0 and parameters: {'learning_rate': 0.05784720168877098, 'num_leaves': 26, 'max_depth': 12, 'min_child_samples': 76, 'lambda_l1': 2.1730643102477583, 'lambda_l2': 3.795095215201849, 'feature_fraction': 0.8739027839036343, 'bagging_fraction': 0.7612636996208504, 'bagging_freq': 6}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[136]\tvalid's map@1: 0.932009\tvalid's map@2: 0.93166\tvalid's map@3: 0.932065\tvalid's map@4: 0.932567\tvalid's map@5: 0.933186\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.93029\tvalid's map@2: 0.930827\tvalid's map@3: 0.931152\tvalid's map@4: 0.9318\tvalid's map@5: 0.932143\n",
      "[200]\tvalid's map@1: 0.931472\tvalid's map@2: 0.931713\tvalid's map@3: 0.931904\tvalid's map@4: 0.932621\tvalid's map@5: 0.933027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:57:34,187] Trial 27 finished with value: 0.0 and parameters: {'learning_rate': 0.044826390368266494, 'num_leaves': 20, 'max_depth': 7, 'min_child_samples': 20, 'lambda_l1': 3.0678273414508346, 'lambda_l2': 4.616143043381388, 'feature_fraction': 0.993271858200303, 'bagging_fraction': 0.8257945775469722, 'bagging_freq': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[179]\tvalid's map@1: 0.931364\tvalid's map@2: 0.932035\tvalid's map@3: 0.932071\tvalid's map@4: 0.932612\tvalid's map@5: 0.933098\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.930934\tvalid's map@2: 0.930317\tvalid's map@3: 0.930961\tvalid's map@4: 0.93192\tvalid's map@5: 0.932481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:57:45,586] Trial 28 finished with value: 0.0 and parameters: {'learning_rate': 0.07363302999071468, 'num_leaves': 44, 'max_depth': 5, 'min_child_samples': 55, 'lambda_l1': 4.364487353293372, 'lambda_l2': 2.5539415142973443, 'feature_fraction': 0.9303281012149861, 'bagging_fraction': 0.6225852818607901, 'bagging_freq': 10}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[142]\tvalid's map@1: 0.932116\tvalid's map@2: 0.931525\tvalid's map@3: 0.931743\tvalid's map@4: 0.932708\tvalid's map@5: 0.933257\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid's map@1: 0.93029\tvalid's map@2: 0.931445\tvalid's map@3: 0.931883\tvalid's map@4: 0.932188\tvalid's map@5: 0.932813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 11:57:58,458] Trial 29 finished with value: 0.0 and parameters: {'learning_rate': 0.06088714097554036, 'num_leaves': 54, 'max_depth': 9, 'min_child_samples': 71, 'lambda_l1': 3.848189615857711, 'lambda_l2': 3.1414837692757795, 'feature_fraction': 0.7679069868351465, 'bagging_fraction': 0.8931321528480576, 'bagging_freq': 9}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid's map@1: 0.931579\tvalid's map@2: 0.93131\tvalid's map@3: 0.931651\tvalid's map@4: 0.932325\tvalid's map@5: 0.932854\n",
      "\n",
      "✅ Best MAP Score: 0.0\n",
      "🏆 Best Hyperparameters:\n",
      "learning_rate: 0.022737040030900227\n",
      "num_leaves: 52\n",
      "max_depth: 4\n",
      "min_child_samples: 66\n",
      "lambda_l1: 3.1204870035499646\n",
      "lambda_l2: 2.4504408908372417\n",
      "feature_fraction: 0.8766530247173325\n",
      "bagging_fraction: 0.9052181436606378\n",
      "bagging_freq: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Step 1: Clean column names\n",
    "df_train.columns = df_train.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "\n",
    "# Step 2: Prepare data\n",
    "X = df_train.drop(columns=['y', 'id1', 'id3', 'id4', 'id5'])\n",
    "y = df_train['y']\n",
    "groups = df_train['id2']\n",
    "\n",
    "# Step 3: Group split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train = X.iloc[train_idx].copy()\n",
    "X_val = X.iloc[val_idx].copy()\n",
    "y_train = y.iloc[train_idx]\n",
    "y_val = y.iloc[val_idx]\n",
    "group_train = groups.iloc[train_idx]\n",
    "group_val = groups.iloc[val_idx]\n",
    "\n",
    "group_train_sizes = group_train.value_counts().sort_index().values\n",
    "group_val_sizes = group_val.value_counts().sort_index().values\n",
    "\n",
    "X_train = X_train.drop(columns=['id2'])\n",
    "X_val = X_val.drop(columns=['id2'])\n",
    "\n",
    "# Step 4: LightGBM datasets\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train, group=group_train_sizes)\n",
    "lgb_val = lgb.Dataset(X_val, label=y_val, group=group_val_sizes)\n",
    "\n",
    "# Step 5: Objective function\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'map',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "        'feature_pre_filter': False,  # ✅ Prevent pre-filtering\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 64),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 5.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 5.0),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10)\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        param,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_val],\n",
    "        valid_names=['valid'],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(50),\n",
    "            lgb.log_evaluation(100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return gbm.best_score['valid'].get('map', 0.0)\n",
    "\n",
    "    # score = gbm.best_score['valid'].get('map')\n",
    "    if score is None:\n",
    "        print(\"⚠️ 'map' metric missing. Found keys:\", gbm.best_score['valid'].keys())\n",
    "        return 0.0\n",
    "    return score\n",
    "\n",
    "# Step 6: Run Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Step 7: Best results\n",
    "print(\"\\n✅ Best MAP Score:\", study.best_value)\n",
    "print(\"🏆 Best Hyperparameters:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96334371-c41b-499b-97a8-815a3a6639ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean feature names again (in case new columns are added later)\n",
    "df_train.columns = df_train.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "\n",
    "# Drop problematic object/datetime columns\n",
    "df_full = df_train.drop(columns=['id1', 'id3', 'id4', 'id5'])\n",
    "\n",
    "# Define features and labels\n",
    "X_full = df_full.drop(columns=['y', 'id2'])\n",
    "y_full = df_full['y']\n",
    "groups_full = df_full['id2']\n",
    "\n",
    "# Compute group sizes\n",
    "group_full_sizes = groups_full.value_counts().sort_index().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20b8a8fb-a3b0-4ca1-84ac-667e603a61d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_full = lgb.Dataset(X_full, label=y_full, group=group_full_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "222dbcee-fffb-4cf4-b43b-6c402e27668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "# Add required fixed parameters\n",
    "best_params.update({\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'map',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'n_jobs': -1,\n",
    "    'feature_pre_filter': False  # important!\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d785a12c-eaab-46d5-b3c9-14d28185e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    lgb_full,\n",
    "    num_boost_round=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "826ceac9-a281-4753-871d-37575f0587ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final MAP Score: 1.00000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "# Step 1: Predict scores\n",
    "y_pred = final_model.predict(X_val)\n",
    "\n",
    "# Step 2: Prepare data for MAP calculation\n",
    "# Group the predictions and true labels back into their original sessions/queries\n",
    "X_val_with_ids = X_val.copy()\n",
    "X_val_with_ids['y_true'] = y_val\n",
    "X_val_with_ids['y_pred'] = y_pred\n",
    "X_val_with_ids['id2'] = df_train['id2'].iloc[X_val.index]  # reattach group ids\n",
    "\n",
    "# Step 3: Compute MAP@K manually\n",
    "average_precisions = []\n",
    "\n",
    "for session_id, group in X_val_with_ids.groupby('id2'):\n",
    "    if group['y_true'].sum() == 0:\n",
    "        continue  # skip groups with no positive labels\n",
    "    sorted_group = group.sort_values('y_pred', ascending=False)\n",
    "    y_true = sorted_group['y_true'].values\n",
    "    average_precision = label_ranking_average_precision_score([y_true], [y_true])\n",
    "    average_precisions.append(average_precision)\n",
    "\n",
    "# Final MAP score\n",
    "final_map_score = np.mean(average_precisions)\n",
    "print(f\"✅ Final MAP Score: {final_map_score:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62390e98-01a0-40f7-8565-b51777a458ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns = df_test.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fccdfd76-2e5d-43de-8153-e003f9b711a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=['id1', 'id2', 'id3', 'id4', 'id5'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ea1eadc-74f6-44f0-a9fa-0ab679359fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['pred'] = final_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6b4924a5-c3ff-4686-87e9-54223901a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved predictions with 'pred' column to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Make sure the test features match the training features\n",
    "X_test = df_test[X_train.columns]  # X_train is the feature matrix used during training\n",
    "\n",
    "# 2. Predict using the final trained model\n",
    "raw_preds = final_model.predict(X_test)\n",
    "\n",
    "# 3. Add raw predictions to df_test\n",
    "df_test['raw_pred'] = raw_preds\n",
    "\n",
    "# 4. Normalize predictions within each group (based on 'id2')\n",
    "#    So values are between 0 and 1 within each group\n",
    "df_test['pred'] = df_test.groupby('id2')['raw_pred'].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    ")\n",
    "\n",
    "# 5. Save to CSV with required columns\n",
    "df_test[['id1', 'id2', 'id3', 'id5', 'pred']].to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved predictions with 'pred' column to predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715f464-3bc3-43b2-b653-2fa5edd4a9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
